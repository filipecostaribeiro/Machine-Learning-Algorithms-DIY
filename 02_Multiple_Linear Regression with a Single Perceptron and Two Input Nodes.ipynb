{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31dd6725-762d-4aca-9e96-cda54d249706",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression with a Single Perceptron and Two Input Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed5624-f559-430d-9c26-302025f01f2f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [What is a Linear Regression using 2 Input Nodes](#1.0)\n",
    "2. [Finding the Parameters](#2.0)\n",
    "   1. [Loss Function(L) and Cost Function(C)](#2.1)\n",
    "   2. [Partial Derivatives](#2.2)\n",
    "   3. [Forward and Back Propagation](#2.3)\n",
    "3. [Implementation](#3.0)\n",
    "   1. [Dataset](#3.1)\n",
    "   2. [Data Preprocessing](#3.2)\n",
    "   3. [Training the Model](#3.3)\n",
    "   4. [Model](#3.4)\n",
    "   5. [Predictions](#3.5)\n",
    "   6. [Comparing results with scikit learn](#3.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503395dc-feb2-4ae7-8a71-942e00bb7683",
   "metadata": {},
   "source": [
    "<a id=\"1.0\"></a>\n",
    "## What is a Linear Regression using 2 Input Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0020967-c90d-4a7a-bd0f-da5a2d59fd0c",
   "metadata": {},
   "source": [
    "A Linear Regression with two input nodes  involves drawing a plane ($\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + b$) that best describes the relationship between three variables.\n",
    "In other words, given a set of x1-axis values and x2-axis values, we aim to predict the corresponding y-axis values. For each prediction, we\n",
    "plug the $x_{1}$ and $x_{2}$ values into the equation of the plane to obtain the predicted value $\\hat{y}$.\n",
    "For each prediction, we calculate the residual error as the difference between the the predicted value $\\hat{y}$ and the observed value $y$.\n",
    "The line that minimizes the sum of the squared residuals is chosen, ensuring that no other line provides a smaller sum.\n",
    "\n",
    "$$\\text{Sum of squared residuals for n predictions} =\\sum_{i=1}^{n} \\left( \\hat{y}_{i} - y_{i} \\right)^2$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b923d-c3b9-4ac1-9c88-09385b46d9c3",
   "metadata": {},
   "source": [
    "<a id=\"2.0\"></a>\n",
    "## Finding the Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843b217-4fc7-4400-9c81-21153b6b56df",
   "metadata": {},
   "source": [
    "For this case, we need to determine the parameters $w_{1}$,$w_{2}$ and $b$. First we must define an equation (the loss function) that measures the error for individual predictions. To optimize the model, we use a cost function, which is the average of the loss function over all training examples. With the cost function defined, in terms of the parameters $w_{1}$,$w_{2}$ and $b$, we can apply gradient descent to find the values that minimize it. This involves calculating the partial derivatives of the cost function with respect to $w_{1}$,$w_{2}$ and $b$ and iteratively updating the parameters in the direction that reduces the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924607f-46c6-4cd4-9bb2-06faf35b38f8",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "### Loss Function(L) and Cost Function(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912c10e-631f-436e-971d-cf23bae35263",
   "metadata": {},
   "source": [
    "$$\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + b$$\n",
    "$$\\text{L} =\\sum_{i=1}^{n} \\left( \\hat{y}_{i} - y_{i} \\right)^2$$\n",
    "$$\\text{C} =\\frac{\\sum_{i=1}^{n} \\left( \\hat{y}_{i} - y_{i} \\right)^2}{n}\\frac{1}{2}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1e3ef-53ac-49ae-b9e1-f00c47368a92",
   "metadata": {},
   "source": [
    "For this case of cost function, we will divide by two merely for convenience, as taking the partial derivative will result in a simpler expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90e1ce-0f45-40ac-9479-830cc464f106",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "### Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26570379-e7c0-49cf-ba89-f8e940dbd5a8",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{C} }{ \\partial w_{1} } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\hat{y}_{i} - y_{i}\\right)x_{1i},\\\\\n",
    "\\frac{\\partial \\mathcal{C} }{ \\partial w_{2} } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\hat{y}_{i} - y_{i}\\right)x_{2i},\\\\\n",
    "\\frac{\\partial \\mathcal{C} }{ \\partial b } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(\\hat{y}_{i} - y_{i}\\right).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6778ed-0a2f-4049-a1d2-c4cd93266a48",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "### Forward and Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc34bd-d284-46aa-a465-1b5369e6f078",
   "metadata": {},
   "source": [
    "The goal at the end of the algorithm is to determine the optimal \n",
    "ùë§ and ùëè\n",
    "\n",
    "Forward Propagation:\n",
    "We must first guess any value for ùë§, and b. \n",
    "typically ùëè is initialized to 0. \n",
    "Using these parameters, we can calculate our initial cost.\n",
    "\n",
    "Backward Propagation:\n",
    "We now determine the corrections for the parameters based on gradient descent:\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha    &= \\text{learning rate}, \\\\\n",
    "w_{(1)2}    &= w_{(1)1} - \\alpha \\frac{\\partial \\mathcal{C}}{ \\partial w_{1}}, \\\\\n",
    "w_{(2)2}    &= w_{(2)1} - \\alpha \\frac{\\partial \\mathcal{C}}{ \\partial w_{2}}, \\\\\n",
    "b_{2}     &= b_{1} - \\alpha \\frac{\\partial \\mathcal{C}}{ \\partial b}.\n",
    "\\end{align}\n",
    "\n",
    "Now, using the new ùë§ and ùëè, we perform the process again for a predetermined number of cycles. The calculated cost should decrease until it converges. Once convergence is achieved, we will have the optimal ùë§ and ùëè."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33204fc4-a17e-4fdb-92c4-e630975ab734",
   "metadata": {},
   "source": [
    "<a id=\"3.0\"></a>\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76db5c82-0b28-4df9-a67e-b7a2da61eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bccafd-3fd7-4f7e-9db0-7bb52c22cc2c",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### Dataset\n",
    "We will use the columns GrLivArea and OverallQual to predict the SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf7dbaa-5980-4027-821f-793e0299b310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/house_prices_train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cae906-e817-4683-8ac4-f5f0ab0429e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1256</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  OverallQual\n",
       "0          1710            7\n",
       "1          1262            6\n",
       "2          1786            7\n",
       "3          1717            7\n",
       "4          2198            8\n",
       "...         ...          ...\n",
       "1455       1647            6\n",
       "1456       2073            6\n",
       "1457       2340            7\n",
       "1458       1078            5\n",
       "1459       1256            5\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_multi = df[['GrLivArea', 'OverallQual']]\n",
    "Y_multi = df['SalePrice']\n",
    "display(X_multi)\n",
    "display(Y_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29112f04-e1cf-4a45-bf98-30f8b13dcef7",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6f69c8-84ed-4aab-b265-111c4c4e4323",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "We need to normalize the values first to help gradient descent converge more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1d8df7-1c87-4a2f-8c3d-69e7bb5c23c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370333</td>\n",
       "      <td>0.651479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.482512</td>\n",
       "      <td>-0.071836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.515013</td>\n",
       "      <td>0.651479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383659</td>\n",
       "      <td>0.651479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.299326</td>\n",
       "      <td>1.374795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.250402</td>\n",
       "      <td>-0.071836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1.061367</td>\n",
       "      <td>-0.071836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.569647</td>\n",
       "      <td>0.651479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>-0.832788</td>\n",
       "      <td>-0.795151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-0.493934</td>\n",
       "      <td>-0.795151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  OverallQual\n",
       "0      0.370333     0.651479\n",
       "1     -0.482512    -0.071836\n",
       "2      0.515013     0.651479\n",
       "3      0.383659     0.651479\n",
       "4      1.299326     1.374795\n",
       "...         ...          ...\n",
       "1455   0.250402    -0.071836\n",
       "1456   1.061367    -0.071836\n",
       "1457   1.569647     0.651479\n",
       "1458  -0.832788    -0.795151\n",
       "1459  -0.493934    -0.795151\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.347273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.515281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>-0.074560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.366161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.077611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>-0.488523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-0.420841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice\n",
       "0      0.347273\n",
       "1      0.007288\n",
       "2      0.536154\n",
       "3     -0.515281\n",
       "4      0.869843\n",
       "...         ...\n",
       "1455  -0.074560\n",
       "1456   0.366161\n",
       "1457   1.077611\n",
       "1458  -0.488523\n",
       "1459  -0.420841\n",
       "\n",
       "[1460 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_multi_norm = pd.DataFrame()\n",
    "Y_multi_norm = pd.DataFrame()\n",
    "X_multi_norm['GrLivArea'] = (df['GrLivArea'] - np.mean(df['GrLivArea']))/np.std(df['GrLivArea'])\n",
    "X_multi_norm['OverallQual'] = (df['OverallQual'] - np.mean(df['OverallQual']))/np.std(df['OverallQual'])\n",
    "Y_multi_norm['SalePrice'] = (df['SalePrice'] - np.mean(df['SalePrice']))/np.std(df['SalePrice'])\n",
    "display(X_multi_norm)\n",
    "display(Y_multi_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dd62b-32f7-4a2f-a579-938dea616382",
   "metadata": {},
   "source": [
    "#### Arranging the values into a matrice form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd424a5-9872-4d14-a5e3-fe7b3bcf0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi_norm = np.array(X_multi_norm)\n",
    "Y_multi_norm = np.array(Y_multi_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b88932-9cca-490a-b51f-db93b3fc3277",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1f6afc-29fd-4f9b-a9c1-10c5295de130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for iteration 1: 0.484088414143908\n",
      "Cost for iteration 2: 0.42374093911200367\n",
      "Cost for iteration 3: 0.3755831836284978\n",
      "Cost for iteration 4: 0.33608422225125445\n",
      "Cost for iteration 5: 0.3033958982271313\n",
      "Cost for iteration 6: 0.27626662953037884\n",
      "Cost for iteration 7: 0.2537307248753134\n",
      "Cost for iteration 8: 0.23500514190184596\n",
      "Cost for iteration 9: 0.21944424622291717\n",
      "Cost for iteration 10: 0.20651283012184762\n",
      "Cost for iteration 11: 0.19576646875214038\n",
      "Cost for iteration 12: 0.18683592278736683\n",
      "Cost for iteration 13: 0.17941436689650497\n",
      "Cost for iteration 14: 0.17324682603731856\n",
      "Cost for iteration 15: 0.16812140973172834\n",
      "Cost for iteration 16: 0.16386203089194756\n",
      "Cost for iteration 17: 0.1603223558340685\n",
      "Cost for iteration 18: 0.1573807767867708\n",
      "Cost for iteration 19: 0.15493623395234138\n",
      "Cost for iteration 20: 0.15290474352665684\n",
      "Cost for iteration 21: 0.15121651238099001\n",
      "Cost for iteration 22: 0.14981354027477606\n",
      "Cost for iteration 23: 0.14864762722081828\n",
      "Cost for iteration 24: 0.14767871754444478\n",
      "Cost for iteration 25: 0.14687352374565832\n",
      "Cost for iteration 26: 0.14620438288618112\n",
      "Cost for iteration 27: 0.14564830621184913\n",
      "Cost for iteration 28: 0.14518618935953534\n",
      "Cost for iteration 29: 0.14480215601476515\n",
      "Cost for iteration 30: 0.14448301247096892\n",
      "Cost for iteration 31: 0.14421779435141274\n",
      "Cost for iteration 32: 0.14399738992115477\n",
      "Cost for iteration 33: 0.14381422704767302\n",
      "Cost for iteration 34: 0.14366201305550044\n",
      "Cost for iteration 35: 0.1435355185374101\n",
      "Cost for iteration 36: 0.14343039769484806\n",
      "Cost for iteration 37: 0.14334303903529685\n",
      "Cost for iteration 38: 0.14327044129718342\n",
      "Cost for iteration 39: 0.14321011033965422\n",
      "Cost for iteration 40: 0.1431599734548012\n",
      "Cost for iteration 41: 0.1431183081584804\n",
      "Cost for iteration 42: 0.14308368301328864\n",
      "Cost for iteration 43: 0.143054908450633\n",
      "Cost for iteration 44: 0.14303099590235518\n",
      "Cost for iteration 45: 0.14301112383785217\n",
      "Cost for iteration 46: 0.14299460953987672\n",
      "Cost for iteration 47: 0.14298088564935793\n",
      "Cost for iteration 48: 0.14296948067342424\n",
      "Cost for iteration 49: 0.14296000278696996\n",
      "Cost for iteration 50: 0.1429521263712579\n",
      "Cost for iteration 51: 0.14294558082708314\n",
      "Cost for iteration 52: 0.1429401412781678\n",
      "Cost for iteration 53: 0.1429356208453951\n",
      "Cost for iteration 54: 0.1429318642264603\n",
      "Cost for iteration 55: 0.14292874236036227\n",
      "Cost for iteration 56: 0.14292614799343203\n",
      "Cost for iteration 57: 0.14292399199456554\n",
      "Cost for iteration 58: 0.14292220029306865\n",
      "Cost for iteration 59: 0.14292071133391201\n",
      "Cost for iteration 60: 0.14291947396296945\n",
      "Cost for iteration 61: 0.1429184456695856\n",
      "Cost for iteration 62: 0.1429175911260959\n",
      "Cost for iteration 63: 0.14291688097412256\n",
      "Cost for iteration 64: 0.14291629081594878\n",
      "Cost for iteration 65: 0.1429158003763202\n",
      "Cost for iteration 66: 0.1429153928058756\n",
      "Cost for iteration 67: 0.14291505410227648\n",
      "Cost for iteration 68: 0.14291477262914823\n",
      "Cost for iteration 69: 0.1429145387163048\n",
      "Cost for iteration 70: 0.14291434432752373\n",
      "Cost for iteration 71: 0.1429141827844564\n",
      "Cost for iteration 72: 0.14291404853718936\n",
      "Cost for iteration 73: 0.14291393697357352\n",
      "Cost for iteration 74: 0.14291384426077086\n",
      "Cost for iteration 75: 0.14291376721357482\n",
      "Cost for iteration 76: 0.14291370318498062\n",
      "Cost for iteration 77: 0.14291364997524578\n",
      "Cost for iteration 78: 0.1429136057563164\n",
      "Cost for iteration 79: 0.14291356900902344\n",
      "Cost for iteration 80: 0.1429135384708906\n",
      "Cost for iteration 81: 0.14291351309276118\n",
      "Cost for iteration 82: 0.14291349200275355\n",
      "Cost for iteration 83: 0.1429134744763073\n",
      "Cost for iteration 84: 0.14291345991129042\n",
      "Cost for iteration 85: 0.14291344780731252\n",
      "Cost for iteration 86: 0.14291343774853393\n",
      "Cost for iteration 87: 0.1429134293893789\n",
      "Cost for iteration 88: 0.1429134224426635\n",
      "Cost for iteration 89: 0.14291341666972893\n",
      "Cost for iteration 90: 0.14291341187224244\n",
      "Cost for iteration 91: 0.1429134078853833\n",
      "Cost for iteration 92: 0.14291340457218046\n",
      "Cost for iteration 93: 0.14291340181880682\n",
      "Cost for iteration 94: 0.14291339953066853\n",
      "Cost for iteration 95: 0.14291339762915506\n",
      "Cost for iteration 96: 0.14291339604893877\n",
      "Cost for iteration 97: 0.14291339473573034\n",
      "Cost for iteration 98: 0.14291339364441366\n",
      "Cost for iteration 99: 0.14291339273749587\n",
      "Cost for iteration 100: 0.14291339198381925\n",
      "Cost for iteration 101: 0.14291339135749076\n",
      "Cost for iteration 102: 0.14291339083699248\n",
      "Cost for iteration 103: 0.14291339040444237\n",
      "Cost for iteration 104: 0.14291339004497988\n",
      "Cost for iteration 105: 0.1429133897462555\n",
      "Cost for iteration 106: 0.14291338949800633\n",
      "Cost for iteration 107: 0.1429133892917036\n",
      "Cost for iteration 108: 0.1429133891202597\n",
      "Cost for iteration 109: 0.14291338897778452\n",
      "Cost for iteration 110: 0.14291338885938323\n",
      "Cost for iteration 111: 0.14291338876098814\n",
      "Cost for iteration 112: 0.1429133886792188\n",
      "Cost for iteration 113: 0.14291338861126596\n",
      "Cost for iteration 114: 0.14291338855479502\n",
      "Cost for iteration 115: 0.14291338850786595\n",
      "Cost for iteration 116: 0.14291338846886645\n",
      "Cost for iteration 117: 0.14291338843645665\n",
      "Cost for iteration 118: 0.14291338840952314\n",
      "Cost for iteration 119: 0.14291338838714052\n",
      "Cost for iteration 120: 0.1429133883685399\n",
      "Cost for iteration 121: 0.1429133883530822\n",
      "Cost for iteration 122: 0.14291338834023637\n",
      "Cost for iteration 123: 0.1429133883295611\n",
      "Cost for iteration 124: 0.14291338832068964\n",
      "Cost for iteration 125: 0.14291338831331715\n",
      "Cost for iteration 126: 0.14291338830719041\n",
      "Cost for iteration 127: 0.14291338830209888\n",
      "Cost for iteration 128: 0.14291338829786765\n",
      "Cost for iteration 129: 0.1429133882943514\n",
      "Cost for iteration 130: 0.14291338829142927\n",
      "Cost for iteration 131: 0.14291338828900088\n",
      "Cost for iteration 132: 0.14291338828698283\n",
      "Cost for iteration 133: 0.14291338828530575\n",
      "Cost for iteration 134: 0.1429133882839121\n",
      "Cost for iteration 135: 0.14291338828275388\n",
      "Cost for iteration 136: 0.14291338828179137\n",
      "Cost for iteration 137: 0.1429133882809915\n",
      "Cost for iteration 138: 0.14291338828032676\n",
      "Cost for iteration 139: 0.14291338827977437\n",
      "Cost for iteration 140: 0.14291338827931535\n",
      "Cost for iteration 141: 0.14291338827893385\n",
      "Cost for iteration 142: 0.1429133882786168\n",
      "Cost for iteration 143: 0.14291338827835334\n",
      "Cost for iteration 144: 0.1429133882781344\n",
      "Cost for iteration 145: 0.14291338827795244\n",
      "Cost for iteration 146: 0.14291338827780123\n",
      "Cost for iteration 147: 0.14291338827767558\n",
      "Cost for iteration 148: 0.14291338827757116\n",
      "Cost for iteration 149: 0.14291338827748437\n",
      "Cost for iteration 150: 0.14291338827741223\n",
      "Cost for iteration 151: 0.14291338827735234\n",
      "Cost for iteration 152: 0.14291338827730252\n",
      "Cost for iteration 153: 0.14291338827726113\n",
      "Cost for iteration 154: 0.14291338827722672\n",
      "Cost for iteration 155: 0.14291338827719813\n",
      "Cost for iteration 156: 0.1429133882771744\n",
      "Cost for iteration 157: 0.14291338827715463\n",
      "Cost for iteration 158: 0.14291338827713826\n",
      "Cost for iteration 159: 0.1429133882771246\n",
      "Cost for iteration 160: 0.14291338827711328\n",
      "Cost for iteration 161: 0.14291338827710387\n",
      "Cost for iteration 162: 0.14291338827709604\n",
      "Cost for iteration 163: 0.14291338827708955\n",
      "Cost for iteration 164: 0.14291338827708414\n",
      "Cost for iteration 165: 0.14291338827707964\n",
      "Cost for iteration 166: 0.14291338827707592\n",
      "Cost for iteration 167: 0.1429133882770728\n",
      "Cost for iteration 168: 0.14291338827707023\n",
      "Cost for iteration 169: 0.1429133882770681\n",
      "Cost for iteration 170: 0.1429133882770663\n",
      "Cost for iteration 171: 0.14291338827706482\n",
      "Cost for iteration 172: 0.14291338827706357\n",
      "Cost for iteration 173: 0.14291338827706257\n",
      "Cost for iteration 174: 0.14291338827706174\n",
      "Cost for iteration 175: 0.14291338827706104\n",
      "Cost for iteration 176: 0.14291338827706043\n",
      "Cost for iteration 177: 0.14291338827705996\n",
      "Cost for iteration 178: 0.14291338827705954\n",
      "Cost for iteration 179: 0.1429133882770592\n",
      "Cost for iteration 180: 0.14291338827705893\n",
      "Cost for iteration 181: 0.1429133882770587\n",
      "Cost for iteration 182: 0.14291338827705852\n",
      "Cost for iteration 183: 0.14291338827705835\n",
      "Cost for iteration 184: 0.1429133882770582\n",
      "Cost for iteration 185: 0.1429133882770581\n",
      "Cost for iteration 186: 0.14291338827705802\n",
      "Cost for iteration 187: 0.14291338827705793\n",
      "Cost for iteration 188: 0.14291338827705788\n",
      "Cost for iteration 189: 0.14291338827705782\n",
      "Cost for iteration 190: 0.14291338827705777\n",
      "Cost for iteration 191: 0.14291338827705774\n",
      "Cost for iteration 192: 0.14291338827705768\n",
      "Cost for iteration 193: 0.14291338827705768\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[0.36950627]\n",
      " [0.57186162]]\n",
      "b: [[1.05851401e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Random initialization of w1 and w2\n",
    "w1 = np.random.randn(1,1)*0.01\n",
    "w2 = np.random.randn(1,1)*0.01\n",
    "# Initiating b as 0\n",
    "b = np.zeros((1,1))\n",
    "# Defining the learning rate\n",
    "lr = 1.2\n",
    "# percentage difference between an error and its subsequent one\n",
    "diff = 0.00000000000000001\n",
    "\n",
    "# cost log for each iteration\n",
    "cost_list = []\n",
    "# counter for each iteration as a list and initial counter_count c\n",
    "count_list = []\n",
    "c = 0\n",
    "# getting the total number of predictions\n",
    "size = X_multi_norm.shape[0]\n",
    "# loop start\n",
    "while True:\n",
    "    w = np.array([w1,w2])\n",
    "    w = w.reshape(-1,1)\n",
    "    # forward propagation\n",
    "    y_hat = np.matmul(X_multi_norm,w) + b\n",
    "        # computing cost for the current iteration\n",
    "    cost = np.sum((y_hat - Y_multi_norm)**2)/(2*size)\n",
    "        # saving the cost value in a list\n",
    "    cost_list.append(cost)\n",
    "\n",
    "    # backward propagation\n",
    "        # partial derivatives\n",
    "    dw1 = 1/size * np.matmul(X_multi_norm.T,(y_hat-Y_multi_norm))[0][0]\n",
    "    dw2 = 1/size * np.matmul(X_multi_norm.T,(y_hat-Y_multi_norm))[1][0]\n",
    "    db = 1/size *np.sum(y_hat - Y_multi_norm)\n",
    "        # updating parameters\n",
    "    w1 = w1 - dw1*lr\n",
    "    w2 = w2 - dw2*lr\n",
    "    b = b - db*lr\n",
    "\n",
    "    #updating counter and saving in a list\n",
    "    c = c + 1\n",
    "    count_list.append(c)\n",
    "    # display the cost for each iteration\n",
    "    print(f'Cost for iteration {c}: {cost}')\n",
    "    \n",
    "    # Checking if the difference between the last two costs is acceptable\n",
    "    if len(cost_list) >1:\n",
    "        if ((cost_list[-2] - cost_list[-1])/cost_list[-2]) < diff:\n",
    "            break\n",
    "        elif c==200:\n",
    "            break\n",
    "\n",
    "# plot the cost for each iteraction\n",
    "plt.plot(count_list,cost_list)\n",
    "plt.show()\n",
    "print(f'w: {w}')\n",
    "print(f'b: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a8e7a-9619-4449-b79c-eaa5c1741110",
   "metadata": {},
   "source": [
    "<a id=\"3.4\"></a>\n",
    "### Model\n",
    "$$\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59a6cb6c-e2fd-48fe-ab4b-b51fdafc88ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.36950627336957415\n",
      "w2 = 0.5718616209793602\n",
      "b = 1.058514007039876e-16\n"
     ]
    }
   ],
   "source": [
    "print(f'w1 = {w[0][0]}')\n",
    "print(f'w2 = {w[1][0]}')\n",
    "print(f'b = {b[0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80031a9-fd79-4ea7-bb8b-606413e514eb",
   "metadata": {},
   "source": [
    "<a id=\"3.5\"></a>\n",
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ea71a2-f74d-4a07-967f-efc1df678087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221375.06803278188, 160036.2865667868, 281596.6050073202]\n"
     ]
    }
   ],
   "source": [
    "# values to predict\n",
    "X_pred = [[1710, 7], [1200, 6], [2200, 8]]\n",
    "\n",
    "\n",
    "X_pred = np.array(X_pred)\n",
    "X1_pred = X_pred[:,0]\n",
    "X2_pred = X_pred[:,1]\n",
    "# values to predict normalized\n",
    "X_pred_norm = []\n",
    "# predicted values normalized\n",
    "Y_pred_norm = []\n",
    "# predicted values denormalized\n",
    "Y_pred = []\n",
    "\n",
    "# normalize values do predict\n",
    "std_x1 = np.std(df['GrLivArea'])\n",
    "ux1 = np.mean(df['GrLivArea'])\n",
    "std_x2 = np.std(df['OverallQual'])\n",
    "ux2 = np.mean(df['OverallQual'])\n",
    "\n",
    "X1_pred = (X1_pred-ux1)/std_x1\n",
    "X2_pred = (X2_pred-ux2)/std_x2\n",
    "    \n",
    "\n",
    "# prediction \n",
    "for n in range(0,X1_pred.size):\n",
    "    Y_pred_norm.append(X1_pred[n]*w[0][0]+X2_pred[n]*w[1][0] +b[0][0] )\n",
    "\n",
    "# denormalize predicted values\n",
    "for n in Y_pred_norm:\n",
    "    Y_pred.append( (n*np.std(df['SalePrice']))+np.mean(df['SalePrice']))\n",
    "\n",
    "print(Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ce302-436e-470b-8a3e-3711f686e383",
   "metadata": {},
   "source": [
    "<a id=\"3.6\"></a>\n",
    "### Comparing results with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8fd763-5a9d-45ed-99c4-b37fcfcf6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df[['GrLivArea', 'OverallQual']]\n",
    "Y_multi = df['SalePrice']\n",
    "X_multi = np.array(X_multi)\n",
    "Y_multi = np.array(Y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5625d487-7170-4ad8-9994-bdd63598f830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_multi,Y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c75bdc-c156-499b-9139-30960cf5160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predicted values model created:[221375.07, 160036.29, 281596.61]\n",
      " Predicted values Scikit Learn:[221375.07, 160036.29, 281596.61]\n"
     ]
    }
   ],
   "source": [
    "X_pred = [[1710, 7], [1200, 6], [2200, 8]]\n",
    "y_pred_2 = model.predict(X_pred)\n",
    "print(f' Predicted values model created:{[round(valor, 2) for valor in Y_pred]}')\n",
    "print(f' Predicted values Scikit Learn:{[round(valor, 2) for valor in y_pred_2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e16205-de70-42cc-95b5-77721c7b4ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
